{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prabhat-Deshmukh022/CNN_dog_cat_classification/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qqWvanYgSdRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a07e71b9-aa7c-421b-b917-b7e10d4b5f59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the zip file\n",
        "zip_file_path = '/content/drive/MyDrive/CNN/Section+40+-+Convolutional+Neural+Networks+(CNN).zip'\n",
        "\n",
        "# Directory where you want to extract the contents\n",
        "extract_dir = '/content/extracted_files'\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(f'Files extracted to {extract_dir}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37UW8wC-o1jw",
        "outputId": "d27940ed-ee5f-41bc-ded0-750984cb3ca8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted to /content/extracted_files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List files in the extracted directory\n",
        "files = os.listdir(extract_dir)\n",
        "print(files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1n7V1wIbpb8d",
        "outputId": "9f17be44-2d6e-43a8-d2d1-dc1a48a72cf3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__MACOSX', 'Section 40 - Convolutional Neural Networks (CNN)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing libraries\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "gWOGb3uYpmio"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data preprocessing\n",
        "#Training set preprocessing -\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   zoom_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   rotation_range=20,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   brightness_range=(0.8, 1.2),\n",
        "                                   )\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/extracted_files/Section 40 - Convolutional Neural Networks (CNN)/dataset/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQA8x-PIBY-7",
        "outputId": "53d720f3-4592-4a4e-865f-2e6e8fab5095"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test set preprocessing -\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/extracted_files/Section 40 - Convolutional Neural Networks (CNN)/dataset/test_set',\n",
        "                                            target_size=(64,64),\n",
        "                                            batch_size=32,\n",
        "                                            class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6Rc8GBmDz1p",
        "outputId": "273caf52-4cdf-4480-82fd-696c2be43875"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initializing the CNN\n",
        "\n",
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "fM5eoPBsFrOK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convolutional layer and Max Pooling\n",
        "\n",
        "\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
        "cnn.add( tf.keras.layers.MaxPool2D(pool_size = 2, strides=2) )"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HvWMESwtGyUF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Second Convolutional Layer\n",
        "\n",
        "cnn.add( tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu') )\n",
        "cnn.add( tf.keras.layers.MaxPool2D(pool_size = 2, strides=2) )"
      ],
      "metadata": {
        "id": "MyMU4v5QJNV4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Flattening\n",
        "\n",
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "MQCd1ND8JTkL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fully Connected Layers\n",
        "\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "RRJhoDbTJ6zd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compiling\n",
        "\n",
        "cnn.compile( optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'] )"
      ],
      "metadata": {
        "id": "u5lDG7sKlbh2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x=training_set, validation_data=test_set, epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7Pk3_N33mIfz",
        "outputId": "e3a38a35-b1fb-4826-a85c-23b0746e714f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "250/250 [==============================] - 63s 247ms/step - loss: 0.6831 - accuracy: 0.5543 - val_loss: 0.6428 - val_accuracy: 0.6225\n",
            "Epoch 2/25\n",
            "250/250 [==============================] - 60s 239ms/step - loss: 0.6541 - accuracy: 0.6110 - val_loss: 0.6088 - val_accuracy: 0.6755\n",
            "Epoch 3/25\n",
            "250/250 [==============================] - 64s 258ms/step - loss: 0.6381 - accuracy: 0.6289 - val_loss: 0.6015 - val_accuracy: 0.6910\n",
            "Epoch 4/25\n",
            "250/250 [==============================] - 61s 242ms/step - loss: 0.6233 - accuracy: 0.6486 - val_loss: 0.5811 - val_accuracy: 0.6935\n",
            "Epoch 5/25\n",
            "250/250 [==============================] - 60s 240ms/step - loss: 0.6173 - accuracy: 0.6593 - val_loss: 0.5905 - val_accuracy: 0.6725\n",
            "Epoch 6/25\n",
            "250/250 [==============================] - 60s 238ms/step - loss: 0.5927 - accuracy: 0.6809 - val_loss: 0.5898 - val_accuracy: 0.6770\n",
            "Epoch 7/25\n",
            "250/250 [==============================] - 63s 251ms/step - loss: 0.5816 - accuracy: 0.6888 - val_loss: 0.5355 - val_accuracy: 0.7310\n",
            "Epoch 8/25\n",
            "250/250 [==============================] - 61s 242ms/step - loss: 0.5817 - accuracy: 0.6895 - val_loss: 0.5993 - val_accuracy: 0.6820\n",
            "Epoch 9/25\n",
            "250/250 [==============================] - 61s 243ms/step - loss: 0.5619 - accuracy: 0.7069 - val_loss: 0.5090 - val_accuracy: 0.7450\n",
            "Epoch 10/25\n",
            "250/250 [==============================] - 60s 240ms/step - loss: 0.5530 - accuracy: 0.7154 - val_loss: 0.5053 - val_accuracy: 0.7505\n",
            "Epoch 11/25\n",
            "250/250 [==============================] - 60s 239ms/step - loss: 0.5432 - accuracy: 0.7239 - val_loss: 0.5004 - val_accuracy: 0.7585\n",
            "Epoch 12/25\n",
            "250/250 [==============================] - 60s 241ms/step - loss: 0.5339 - accuracy: 0.7284 - val_loss: 0.4724 - val_accuracy: 0.7790\n",
            "Epoch 13/25\n",
            "250/250 [==============================] - 60s 242ms/step - loss: 0.5360 - accuracy: 0.7229 - val_loss: 0.4766 - val_accuracy: 0.7690\n",
            "Epoch 14/25\n",
            "250/250 [==============================] - 60s 241ms/step - loss: 0.5264 - accuracy: 0.7316 - val_loss: 0.4667 - val_accuracy: 0.7845\n",
            "Epoch 15/25\n",
            "250/250 [==============================] - 60s 241ms/step - loss: 0.5256 - accuracy: 0.7296 - val_loss: 0.5017 - val_accuracy: 0.7575\n",
            "Epoch 16/25\n",
            "250/250 [==============================] - 60s 240ms/step - loss: 0.5144 - accuracy: 0.7455 - val_loss: 0.4658 - val_accuracy: 0.7705\n",
            "Epoch 17/25\n",
            "250/250 [==============================] - 64s 255ms/step - loss: 0.5036 - accuracy: 0.7455 - val_loss: 0.4844 - val_accuracy: 0.7690\n",
            "Epoch 18/25\n",
            "250/250 [==============================] - 61s 244ms/step - loss: 0.5054 - accuracy: 0.7489 - val_loss: 0.5065 - val_accuracy: 0.7275\n",
            "Epoch 19/25\n",
            "250/250 [==============================] - 61s 244ms/step - loss: 0.4996 - accuracy: 0.7574 - val_loss: 0.4428 - val_accuracy: 0.7890\n",
            "Epoch 20/25\n",
            "250/250 [==============================] - 60s 240ms/step - loss: 0.4986 - accuracy: 0.7523 - val_loss: 0.4920 - val_accuracy: 0.7580\n",
            "Epoch 21/25\n",
            "250/250 [==============================] - 62s 247ms/step - loss: 0.4859 - accuracy: 0.7575 - val_loss: 0.4400 - val_accuracy: 0.7985\n",
            "Epoch 22/25\n",
            "250/250 [==============================] - 60s 241ms/step - loss: 0.4897 - accuracy: 0.7649 - val_loss: 0.4430 - val_accuracy: 0.7980\n",
            "Epoch 23/25\n",
            "250/250 [==============================] - 60s 238ms/step - loss: 0.4767 - accuracy: 0.7695 - val_loss: 0.4285 - val_accuracy: 0.8075\n",
            "Epoch 24/25\n",
            "250/250 [==============================] - 60s 239ms/step - loss: 0.4775 - accuracy: 0.7673 - val_loss: 0.4305 - val_accuracy: 0.8030\n",
            "Epoch 25/25\n",
            "250/250 [==============================] - 60s 242ms/step - loss: 0.4799 - accuracy: 0.7739 - val_loss: 0.4580 - val_accuracy: 0.7940\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7aa00c255390>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/content/extracted_files/Section 40 - Convolutional Neural Networks (CNN)/dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiTV-ShRm6xX",
        "outputId": "183dd75d-f679-4be6-fb41-0ffcc41423bc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 131ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUrKqxo0PvHD",
        "outputId": "d43a70d1-ce4d-4f87-d6a9-70bfc75e26e9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YHJ3lJzXPz1y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvbsAtiKWNbBHXU5Ic60Si",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}